{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soynlp로 자연어 처리\n",
    "* https://github.com/lovit/soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력이 너무 길어지지 않게하기 위해 찍지 않도록 했으나 \n",
    "# 실제 학습 할 때는 아래 두 줄을 주석처리 하는 것을 권장한다.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n",
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8029, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petitions = pd.read_csv('data/petition_sampled.csv')\n",
    "# 데이터의 크기가 어느정도인지 본다.\n",
    "petitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answered</th>\n",
       "      <th>votes</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>일자리</td>\n",
       "      <td>국토교통부와 한국주택협회가 행한 부당한 행위와 권력남용에 대한 내용을 청원드립니다.</td>\n",
       "      <td>안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>살려주세요..</td>\n",
       "      <td>안녕하십니까?\\n저는 올해 63세된 홀로 사는 늙은 여자입니다...\\n작년 중복날 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>고등학교 교육 내용 수준을 낮춰주시고 실용적인 내용을 담아주세요!</td>\n",
       "      <td>저는 광주에 사는 중3 학생입니다. 고등학교 가기 직전의 학년이라 어느 때보다 고등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>기타</td>\n",
       "      <td>한국문화에 창조적요소를 심자</td>\n",
       "      <td>안녕하십니까\\n저는 92년 한국을 알게된  종국동포 입니다.\\n[저는 한 중소기업에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>외교/통일/국방</td>\n",
       "      <td>다문화정책 및 할랄 인증 제도</td>\n",
       "      <td>대한민국과 국민을 위해 밤낮 없이 수고하시는 대통령을 비롯한 위정자 분들께\\n대한민...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id       start         end  answered  votes  category  \\\n",
       "0          58  2017-08-19  2017-11-17         0     21       일자리   \n",
       "1          63  2017-08-20  2017-09-04         0      1      보건복지   \n",
       "2         136  2017-08-20  2017-11-18         0      4     육아/교육   \n",
       "3         141  2017-08-20  2017-08-27         0      0        기타   \n",
       "4         148  2017-08-20  2017-11-18         0      7  외교/통일/국방   \n",
       "\n",
       "                                            title  \\\n",
       "0  국토교통부와 한국주택협회가 행한 부당한 행위와 권력남용에 대한 내용을 청원드립니다.   \n",
       "1                                         살려주세요..   \n",
       "2            고등학교 교육 내용 수준을 낮춰주시고 실용적인 내용을 담아주세요!   \n",
       "3                                 한국문화에 창조적요소를 심자   \n",
       "4                                다문화정책 및 할랄 인증 제도   \n",
       "\n",
       "                                             content  \n",
       "0  안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...  \n",
       "1  안녕하십니까?\\n저는 올해 63세된 홀로 사는 늙은 여자입니다...\\n작년 중복날 ...  \n",
       "2  저는 광주에 사는 중3 학생입니다. 고등학교 가기 직전의 학년이라 어느 때보다 고등...  \n",
       "3  안녕하십니까\\n저는 92년 한국을 알게된  종국동포 입니다.\\n[저는 한 중소기업에...  \n",
       "4  대한민국과 국민을 위해 밤낮 없이 수고하시는 대통령을 비롯한 위정자 분들께\\n대한민...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petitions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "petitions_content = ' '.join(str(petitions['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentences:\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        self.length = 0\n",
    "    def __iter__(self):\n",
    "        for doc in self.fname:\n",
    "            doc = doc.strip()\n",
    "            if not doc:\n",
    "                continue\n",
    "            for sent in doc.split(' '):\n",
    "                yield sent\n",
    "    def __len__(self):\n",
    "        if self.length == 0:\n",
    "            for doc in self.fname:\n",
    "                doc = doc.strip()\n",
    "                if not doc:\n",
    "                    continue\n",
    "                self.length += len(doc.split(' '))\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sentences = 2633\n"
     ]
    }
   ],
   "source": [
    "corpus_fname = petitions_content\n",
    "sentences = Sentences(corpus_fname)\n",
    "print('num sentences = %d' % len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sentences = 37956\n"
     ]
    }
   ],
   "source": [
    "corpus_fname = petitions['title']\n",
    "sentences = Sentences(corpus_fname)\n",
    "print('num sentences = %d' % len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.114 Gb\n",
      "all cohesion probabilities was computed. # words = 101\n",
      "all branching entropies was computed # words = 91\n",
      "all accessor variety was computed # words = 91\n",
      "CPU times: user 544 ms, sys: 62 ms, total: 606 ms\n",
      "Wall time: 721 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(min_count=100,\n",
    "                               min_cohesion_forward=0.05, \n",
    "                               min_right_branching_entropy=0.0)\n",
    "\n",
    "word_extractor.train(sentences)\n",
    "words = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'신': Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=189, rightside_frequency=0),\n",
       " '와': Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=0, rightside_frequency=164),\n",
       " '용': Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=0, rightside_frequency=120),\n",
       " '평': Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=126, rightside_frequency=0),\n",
       " '학': Scores(cohesion_forward=0, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=125, rightside_frequency=0)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "dict(itertools.islice(words.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scores(cohesion_forward=0.4335347432024169, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=287, rightside_frequency=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words['국민']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words는 {word:Score} 형식의 dictionary입니다. Score는 soynlp/word.py에 구현되어있는 namedtuple입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'soynlp.word._word.Scores'>\n",
      "\n",
      "Scores(cohesion_forward=0.7862404931722864, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=0, left_accessor_variety=0, right_accessor_variety=0, leftside_frequency=261, rightside_frequency=0)\n"
     ]
    }
   ],
   "source": [
    "print('type: %s\\n' % type(words['가상화폐']))\n",
    "print(words['가상화폐'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'soynlp.word._word.Scores'>\n",
      "\n",
      "Scores(cohesion_forward=0.5051440329218106, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=-0.0, left_accessor_variety=0, right_accessor_variety=1, leftside_frequency=491, rightside_frequency=0)\n"
     ]
    }
   ],
   "source": [
    "print('type: %s\\n' % type(words['청원']))\n",
    "print(words['청원'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어   (빈도수, cohesion, branching entropy)\n",
      "\n",
      "청소년     (346, 0.597, 0.692)\n",
      "폐지     (570, 0.857, -0.000)\n",
      "합니다     (195, 0.823, -0.000)\n",
      "출국금지     (321, 0.809, 0.000)\n",
      "처벌     (251, 0.789, 0.000)\n",
      "바랍니다     (102, 0.787, 0.000)\n",
      "가상화폐     (261, 0.786, 0.000)\n",
      "반대합니다     (166, 0.780, 0.000)\n",
      "반대     (344, 0.766, -0.000)\n",
      "만들어     (102, 0.749, 0.000)\n",
      "부탁드립니다     (101, 0.747, 0.000)\n",
      "이명박     (537, 0.731, 0.000)\n",
      "합니     (210, 0.729, -0.000)\n",
      "가상화     (282, 0.725, -0.000)\n",
      "합니다.     (106, 0.717, 0.000)\n",
      "해주세요     (215, 0.715, 0.000)\n",
      "소년법     (179, 0.712, 0.000)\n",
      "청원합니다     (238, 0.703, -0.000)\n",
      "문재인     (139, 0.685, 0.000)\n",
      "금지     (160, 0.675, 0.000)\n",
      "청원합니다.     (130, 0.669, 0.000)\n",
      "주세요     (257, 0.665, 0.000)\n",
      "출국     (400, 0.660, -0.000)\n",
      "만들     (119, 0.654, -0.000)\n",
      "청소년보호법     (112, 0.649, 0.000)\n",
      "조두순     (186, 0.624, 0.000)\n",
      "요청     (137, 0.614, 0.000)\n",
      "국회의원     (100, 0.533, 0.000)\n",
      "청원     (491, 0.505, -0.000)\n",
      "부탁드     (108, 0.498, -0.000)\n"
     ]
    }
   ],
   "source": [
    "def word_score(score):\n",
    "    import math\n",
    "    return (score.cohesion_forward * math.exp(score.right_branching_entropy))\n",
    "\n",
    "print('단어   (빈도수, cohesion, branching entropy)\\n')\n",
    "for word, score in sorted(words.items(), key=lambda x:word_score(x[1]), reverse=True)[:30]:\n",
    "    print('%s     (%d, %.3f, %.3f)' % (word, \n",
    "                                   score.leftside_frequency, \n",
    "                                   score.cohesion_forward,\n",
    "                                   score.right_branching_entropy\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scores(cohesion_forward=0.4982728791224398, cohesion_backward=0, left_branching_entropy=0, right_branching_entropy=-0.0, left_accessor_variety=0, right_accessor_variety=1, leftside_frequency=108, rightside_frequency=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<soynlp.tokenizer._tokenizer.RegexTokenizer at 0x113a20390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import RegexTokenizer, LTokenizer, MaxScoreTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고등학교 교육 내용 수준을 낮춰주시고 실용적인 내용을 담아주세요!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_title = petitions['title'][2]\n",
    "sample_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"저는 광주에 사는 중3 학생입니다. 고등학교 가기 직전의 학년이라 어느 때보다 고등학교 선행학습을 학원다니며 치열하게 하고 있고 주위로부터 고등학교에 가면 국어가 어렵다느니 수학이 어렵다느니 과학이 어렵다느니 이런 말을 많이 듣고 있습니다. 실제로 제가 고등학교 선행학습을 하면 국어, 수학, 영어가 중학교에서 배우던 내용과 다르게 수준이 갑자기 올라가서 ' 아 정말 고등학교를 선행 안 하고 가면 성적이 안나오고 힘들다는 말이 그 말이구나'하는 생각이 듭니다. 고등학교 교육 내용 수준을 낮춰주세요. 그리고 솔직히 말해서 고등학교에서 배우는 내용들은 정말 생활 속에서 잘 쓰이지 않는 것 같아 배울 때 체감도도 떨어지는 것 같습니다. 예를 들어 수학의 미적분 내용은 수학을 전문적으로 다루는 사람이 아니면 실생활에서 사용되지 않는 것 같습니다. 저는 실생활에서 정말 잘 쓰이고 꼭 알아야 될 것들을 배워야 한다고 생각합니다. 고등학교를 위해 제 주변에서도 수 많은 친구들이 선행학습 위해 학원을 다니느라 스트레스도 많이 받습니다. 고등학교 교육 내용을 바꾼다면 사교육도 줄어들지 않을까요\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_content = petitions['content'][2]\n",
    "sample_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고등학교', '교육', '내용', '수준을', '낮춰주시고', '실용적인', '내용을', '담아주세요', '!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokened_title = tokenizer.tokenize(sample_title)\n",
    "tokened_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['저는', '광주에', '사는', '중', '3', '학생입니다', '.', '고등학교', '가기', '직전의']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokened_content = tokenizer.tokenize(sample_content)\n",
    "tokened_content[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "print(len(tokened_title))\n",
    "print(len(tokened_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def preprocessing(text):\n",
    "    # HTML 제거\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    # 개행문자 제거\n",
    "    text = re.sub('\\\\\\\\n', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 719 ms, sys: 89.7 ms, total: 808 ms\n",
      "Wall time: 854 ms\n"
     ]
    }
   ],
   "source": [
    "%time sentences = petitions['content'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.27 s, sys: 117 ms, total: 7.39 s\n",
      "Wall time: 7.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [안녕하세요, ?, 존경하고, 지지하는, 문재인, 대통령님, !, 저는, 성남시, ...\n",
       "1    [안녕하십니까, ?, 저는, 올해, 63, 세된, 홀로, 사는, 늙은, 여자입니다,...\n",
       "2    [저는, 광주에, 사는, 중, 3, 학생입니다, ., 고등학교, 가기, 직전의, 학...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sentences = sentences.apply(tokenizer.tokenize)\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['저는', '광주에', '사는', '중', '3', '학생입니다', '.', '고등학교', '가기', '직전의']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-20 09:27:07,183 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2018-05-20 09:27:07,188 : INFO : collecting all words and their counts\n",
      "2018-05-20 09:27:07,190 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-20 09:27:07,645 : INFO : collected 206569 word types from a corpus of 998862 raw words and 8029 sentences\n",
      "2018-05-20 09:27:07,646 : INFO : Loading a fresh vocabulary\n",
      "2018-05-20 09:27:08,654 : INFO : min_count=1 retains 206569 unique words (100% of original 206569, drops 0)\n",
      "2018-05-20 09:27:08,657 : INFO : min_count=1 leaves 998862 word corpus (100% of original 998862, drops 0)\n",
      "2018-05-20 09:27:09,269 : INFO : deleting the raw counts dictionary of 206569 items\n",
      "2018-05-20 09:27:09,274 : INFO : sample=0.001 downsamples 14 most-common words\n",
      "2018-05-20 09:27:09,275 : INFO : downsampling leaves estimated 928590 word corpus (93.0% of prior 998862)\n",
      "2018-05-20 09:27:09,277 : INFO : estimated required memory for 206569 words and 100 dimensions: 268539700 bytes\n",
      "2018-05-20 09:27:09,918 : INFO : resetting layer weights\n",
      "2018-05-20 09:27:12,540 : INFO : training model with 3 workers on 206569 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-05-20 09:27:13,558 : INFO : PROGRESS: at 15.85% examples, 705100 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-20 09:27:14,562 : INFO : PROGRESS: at 30.61% examples, 702081 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-20 09:27:15,573 : INFO : PROGRESS: at 46.73% examples, 708538 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-20 09:27:16,575 : INFO : PROGRESS: at 61.79% examples, 709703 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-20 09:27:17,599 : INFO : PROGRESS: at 77.30% examples, 708644 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-20 09:27:18,604 : INFO : PROGRESS: at 93.04% examples, 711460 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-20 09:27:19,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-20 09:27:19,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-20 09:27:19,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-20 09:27:19,303 : INFO : training on 4994310 raw words (4643174 effective words) took 6.8s, 686887 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x113a200b8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "model = word2vec.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-20 09:27:19,314 : INFO : saving Word2Vec object under 1minwords, separately None\n",
      "2018-05-20 09:27:19,316 : INFO : storing np array 'syn0' to 1minwords.wv.syn0.npy\n",
      "2018-05-20 09:27:19,440 : INFO : not storing attribute syn0norm\n",
      "2018-05-20 09:27:19,442 : INFO : storing np array 'syn1neg' to 1minwords.syn1neg.npy\n",
      "2018-05-20 09:27:19,557 : INFO : not storing attribute cum_table\n",
      "2018-05-20 09:27:20,150 : INFO : saved 1minwords\n"
     ]
    }
   ],
   "source": [
    "model_name = '1minwords'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0440398 , -1.0443611 , -0.5516773 ,  0.6102202 ,  1.8554325 ,\n",
       "        0.06375427,  1.6854692 ,  0.5142126 , -1.3391005 , -0.32294902,\n",
       "       -0.68601817,  1.5004176 , -0.24300487,  0.18031558, -0.51142156,\n",
       "       -0.08511166,  0.7174916 , -0.3621651 ,  1.3833635 ,  0.55446476,\n",
       "       -0.9949153 , -0.7331671 ,  0.59646815, -0.7953661 ,  0.0874754 ,\n",
       "        1.5770007 ,  0.88728523, -1.6485964 ,  0.4021291 , -0.49264896,\n",
       "       -1.1193633 ,  0.6225354 , -0.31333858,  0.19409972,  0.1427176 ,\n",
       "        1.3675289 ,  1.2637956 , -0.07709076, -0.11442575,  0.1845911 ,\n",
       "        1.0062613 ,  0.8003481 ,  0.13619499, -1.2933979 , -0.2974665 ,\n",
       "       -0.9859013 ,  0.5246085 ,  1.1209651 , -0.56296647,  0.44686767,\n",
       "       -0.8310985 ,  0.21361355, -0.2939626 , -0.3863641 ,  0.40865374,\n",
       "       -0.8398327 , -0.37009218,  0.5751925 ,  0.8027985 , -1.1924516 ,\n",
       "       -0.81842595, -0.16124794, -0.1353309 ,  0.09152485, -1.2814677 ,\n",
       "       -0.47796848, -0.63738215, -0.5891517 , -1.1685637 , -0.13298802,\n",
       "       -0.1318088 ,  0.8109074 ,  1.3607583 , -0.8923239 , -1.3230534 ,\n",
       "       -0.20939963, -0.31289393,  0.72388613,  0.6701767 , -0.16027182,\n",
       "       -0.5758438 , -0.6257701 , -0.4986855 , -0.8865739 , -0.56242603,\n",
       "       -1.5547011 ,  1.0611228 ,  0.22943038,  0.02928122, -0.14959215,\n",
       "        1.4962488 ,  0.13634737, -0.19038917, -0.15690309, -0.8034619 ,\n",
       "        1.7848115 , -0.31008127, -0.9929502 ,  1.728852  , -0.271247  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['청원']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-20 09:27:20,168 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'답변'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도가 없는 단어 추출\n",
    "model.wv.doesnt_match('국민 청원 답변 전안법'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'김정은'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도가 없는 단어 추출\n",
    "model.wv.doesnt_match('이명박 박근혜 대통령 김정은'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'전안법'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도가 없는 단어 추출\n",
    "model.wv.doesnt_match('전안법 전기 안전 의류 교통'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('하죠', 0.990835964679718),\n",
       " ('말로만', 0.9899716973304749),\n",
       " ('뉴스보면', 0.9896503686904907),\n",
       " ('그냥', 0.989278256893158),\n",
       " ('뭐합니까', 0.9889724850654602),\n",
       " ('묻고싶습니다', 0.9882982969284058),\n",
       " ('이거', 0.9879079461097717),\n",
       " ('청소년이라고', 0.9877943396568298),\n",
       " ('안됩니다', 0.9875889420509338),\n",
       " ('그러니까', 0.9872233271598816)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 유사한 단어를 추출\n",
    "model.wv.most_similar('전안법')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('박근혜', 0.9973636865615845),\n",
       " ('평소', 0.995707094669342),\n",
       " ('대통령의', 0.9951146841049194),\n",
       " ('노무현', 0.994614839553833),\n",
       " ('정부', 0.9944683313369751),\n",
       " ('개인적인', 0.9943782687187195),\n",
       " ('청와대', 0.9940354228019714),\n",
       " ('군에', 0.9939010739326477),\n",
       " ('언론이나', 0.9935199618339539),\n",
       " ('법률을', 0.993385910987854)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 유사한 단어를 추출\n",
    "model.wv.most_similar('대통령')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('명백히', 0.99812912940979),\n",
       " ('사건이', 0.9979899525642395),\n",
       " ('폐쇄', 0.9979604482650757),\n",
       " ('블록체인', 0.9978711009025574),\n",
       " ('기존의', 0.9978052973747253),\n",
       " ('보면', 0.9977903366088867),\n",
       " ('취지는', 0.997608482837677),\n",
       " ('학교는', 0.9975537061691284),\n",
       " ('내용으로', 0.9974758625030518),\n",
       " ('사건을', 0.9973389506340027)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 유사한 단어를 추출\n",
    "model.wv.most_similar('가상화폐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
